{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45579 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Epoch 1/80\n",
      "448/448 [==============================] - 181s 403ms/step - loss: 1.7446 - accuracy: 0.3178 - val_loss: 1.7667 - val_accuracy: 0.2740\n",
      "Epoch 2/80\n",
      "448/448 [==============================] - 191s 426ms/step - loss: 1.5800 - accuracy: 0.3923 - val_loss: 1.5724 - val_accuracy: 0.3908\n",
      "Epoch 3/80\n",
      "448/448 [==============================] - 182s 407ms/step - loss: 1.4742 - accuracy: 0.4388 - val_loss: 1.4978 - val_accuracy: 0.4265\n",
      "Epoch 4/80\n",
      "448/448 [==============================] - 186s 415ms/step - loss: 1.3987 - accuracy: 0.4740 - val_loss: 1.4314 - val_accuracy: 0.4474\n",
      "Epoch 5/80\n",
      "448/448 [==============================] - 192s 428ms/step - loss: 1.3454 - accuracy: 0.4933 - val_loss: 1.3967 - val_accuracy: 0.4639\n",
      "Epoch 6/80\n",
      "448/448 [==============================] - 196s 437ms/step - loss: 1.2946 - accuracy: 0.5105 - val_loss: 1.3348 - val_accuracy: 0.4862\n",
      "Epoch 7/80\n",
      "448/448 [==============================] - 194s 433ms/step - loss: 1.2491 - accuracy: 0.5241 - val_loss: 1.2928 - val_accuracy: 0.4979\n",
      "Epoch 8/80\n",
      "448/448 [==============================] - 186s 415ms/step - loss: 1.2083 - accuracy: 0.5449 - val_loss: 1.2613 - val_accuracy: 0.5141\n",
      "Epoch 9/80\n",
      "448/448 [==============================] - 186s 414ms/step - loss: 1.1820 - accuracy: 0.5563 - val_loss: 1.2298 - val_accuracy: 0.5292\n",
      "Epoch 10/80\n",
      "448/448 [==============================] - 187s 418ms/step - loss: 1.1449 - accuracy: 0.5722 - val_loss: 1.1991 - val_accuracy: 0.5396\n",
      "Epoch 11/80\n",
      "448/448 [==============================] - 185s 412ms/step - loss: 1.1264 - accuracy: 0.5783 - val_loss: 1.1637 - val_accuracy: 0.5566\n",
      "Epoch 12/80\n",
      "448/448 [==============================] - 185s 413ms/step - loss: 1.0961 - accuracy: 0.5899 - val_loss: 1.1697 - val_accuracy: 0.5511\n",
      "Epoch 13/80\n",
      "448/448 [==============================] - 186s 414ms/step - loss: 1.0681 - accuracy: 0.6033 - val_loss: 1.1558 - val_accuracy: 0.5605\n",
      "Epoch 14/80\n",
      "448/448 [==============================] - 190s 425ms/step - loss: 1.0462 - accuracy: 0.6081 - val_loss: 1.1706 - val_accuracy: 0.5569\n",
      "Epoch 15/80\n",
      "448/448 [==============================] - 181s 405ms/step - loss: 1.0226 - accuracy: 0.6192 - val_loss: 1.1204 - val_accuracy: 0.5753\n",
      "Epoch 16/80\n",
      "448/448 [==============================] - 180s 402ms/step - loss: 1.0020 - accuracy: 0.6307 - val_loss: 1.0908 - val_accuracy: 0.5891\n",
      "Epoch 17/80\n",
      "448/448 [==============================] - 186s 414ms/step - loss: 0.9793 - accuracy: 0.6426 - val_loss: 1.0817 - val_accuracy: 0.5915\n",
      "Epoch 18/80\n",
      "448/448 [==============================] - 188s 421ms/step - loss: 0.9646 - accuracy: 0.6435 - val_loss: 1.0591 - val_accuracy: 0.6002\n",
      "Epoch 19/80\n",
      "448/448 [==============================] - 189s 423ms/step - loss: 0.9407 - accuracy: 0.6539 - val_loss: 1.0575 - val_accuracy: 0.6009\n",
      "Epoch 20/80\n",
      "448/448 [==============================] - 210s 470ms/step - loss: 0.9183 - accuracy: 0.6621 - val_loss: 1.0348 - val_accuracy: 0.6154\n",
      "Epoch 21/80\n",
      "448/448 [==============================] - 191s 426ms/step - loss: 0.8920 - accuracy: 0.6719 - val_loss: 1.0406 - val_accuracy: 0.6034\n",
      "Epoch 22/80\n",
      "448/448 [==============================] - 188s 419ms/step - loss: 0.8792 - accuracy: 0.6780 - val_loss: 1.0218 - val_accuracy: 0.6170\n",
      "Epoch 23/80\n",
      "448/448 [==============================] - 185s 412ms/step - loss: 0.8620 - accuracy: 0.6851 - val_loss: 1.0184 - val_accuracy: 0.6131\n",
      "Epoch 24/80\n",
      "448/448 [==============================] - 184s 410ms/step - loss: 0.8380 - accuracy: 0.6963 - val_loss: 0.9944 - val_accuracy: 0.6320\n",
      "Epoch 25/80\n",
      "448/448 [==============================] - 187s 418ms/step - loss: 0.8111 - accuracy: 0.7064 - val_loss: 0.9898 - val_accuracy: 0.6306\n",
      "Epoch 26/80\n",
      "448/448 [==============================] - 184s 411ms/step - loss: 0.7965 - accuracy: 0.7118 - val_loss: 0.9773 - val_accuracy: 0.6381\n",
      "Epoch 27/80\n",
      "448/448 [==============================] - 184s 412ms/step - loss: 0.7720 - accuracy: 0.7214 - val_loss: 0.9709 - val_accuracy: 0.6419\n",
      "Epoch 28/80\n",
      "448/448 [==============================] - 188s 420ms/step - loss: 0.7495 - accuracy: 0.7305 - val_loss: 0.9498 - val_accuracy: 0.6487\n",
      "Epoch 29/80\n",
      "448/448 [==============================] - 189s 423ms/step - loss: 0.7366 - accuracy: 0.7341 - val_loss: 0.9648 - val_accuracy: 0.6437\n",
      "Epoch 30/80\n",
      "448/448 [==============================] - 187s 417ms/step - loss: 0.7184 - accuracy: 0.7431 - val_loss: 0.9529 - val_accuracy: 0.6537\n",
      "Epoch 31/80\n",
      "448/448 [==============================] - 185s 414ms/step - loss: 0.6958 - accuracy: 0.7532 - val_loss: 0.9276 - val_accuracy: 0.6629\n",
      "Epoch 32/80\n",
      "448/448 [==============================] - 184s 411ms/step - loss: 0.6819 - accuracy: 0.7562 - val_loss: 0.9210 - val_accuracy: 0.6663\n",
      "Epoch 33/80\n",
      "448/448 [==============================] - 187s 418ms/step - loss: 0.6599 - accuracy: 0.7637 - val_loss: 0.9018 - val_accuracy: 0.6688\n",
      "Epoch 34/80\n",
      "448/448 [==============================] - 186s 416ms/step - loss: 0.6464 - accuracy: 0.7672 - val_loss: 0.9051 - val_accuracy: 0.6765\n",
      "Epoch 35/80\n",
      "448/448 [==============================] - 186s 416ms/step - loss: 0.6253 - accuracy: 0.7797 - val_loss: 0.9030 - val_accuracy: 0.6789\n",
      "Epoch 36/80\n",
      "448/448 [==============================] - 175s 391ms/step - loss: 0.6147 - accuracy: 0.7784 - val_loss: 0.8824 - val_accuracy: 0.6872\n",
      "Epoch 37/80\n",
      "448/448 [==============================] - 176s 393ms/step - loss: 0.5929 - accuracy: 0.7874 - val_loss: 0.9218 - val_accuracy: 0.6766\n",
      "Epoch 38/80\n",
      "448/448 [==============================] - 175s 391ms/step - loss: 0.5865 - accuracy: 0.7909 - val_loss: 0.8758 - val_accuracy: 0.6955\n",
      "Epoch 39/80\n",
      "448/448 [==============================] - 176s 393ms/step - loss: 0.5598 - accuracy: 0.8022 - val_loss: 0.8596 - val_accuracy: 0.7013\n",
      "Epoch 40/80\n",
      "448/448 [==============================] - 179s 399ms/step - loss: 0.5430 - accuracy: 0.8066 - val_loss: 0.8648 - val_accuracy: 0.6963\n",
      "Epoch 41/80\n",
      "448/448 [==============================] - 175s 390ms/step - loss: 0.5221 - accuracy: 0.8152 - val_loss: 0.8631 - val_accuracy: 0.6989\n",
      "Epoch 42/80\n",
      "448/448 [==============================] - 174s 390ms/step - loss: 0.5155 - accuracy: 0.8174 - val_loss: 0.8484 - val_accuracy: 0.7115\n",
      "Epoch 43/80\n",
      "448/448 [==============================] - 176s 392ms/step - loss: 0.5048 - accuracy: 0.8215 - val_loss: 0.8770 - val_accuracy: 0.7024\n",
      "Epoch 44/80\n",
      "448/448 [==============================] - 176s 394ms/step - loss: 0.4858 - accuracy: 0.8284 - val_loss: 0.8561 - val_accuracy: 0.7102\n",
      "Epoch 45/80\n",
      "448/448 [==============================] - 176s 393ms/step - loss: 0.4691 - accuracy: 0.8346 - val_loss: 0.8301 - val_accuracy: 0.7169\n",
      "Epoch 46/80\n",
      "448/448 [==============================] - 176s 392ms/step - loss: 0.4608 - accuracy: 0.8355 - val_loss: 0.8633 - val_accuracy: 0.7114\n",
      "Epoch 47/80\n",
      "448/448 [==============================] - 176s 393ms/step - loss: 0.4470 - accuracy: 0.8393 - val_loss: 0.8234 - val_accuracy: 0.7247\n",
      "Epoch 48/80\n",
      "448/448 [==============================] - 177s 394ms/step - loss: 0.4328 - accuracy: 0.8485 - val_loss: 0.8651 - val_accuracy: 0.7126\n",
      "Epoch 49/80\n",
      "448/448 [==============================] - 178s 398ms/step - loss: 0.4238 - accuracy: 0.8501 - val_loss: 0.8404 - val_accuracy: 0.7221\n",
      "Epoch 50/80\n",
      "448/448 [==============================] - 177s 395ms/step - loss: 0.4101 - accuracy: 0.8537 - val_loss: 0.8308 - val_accuracy: 0.7292\n",
      "Epoch 51/80\n",
      "448/448 [==============================] - 175s 390ms/step - loss: 0.4054 - accuracy: 0.8568 - val_loss: 0.8139 - val_accuracy: 0.7372\n",
      "Epoch 52/80\n",
      "448/448 [==============================] - 171s 382ms/step - loss: 0.3960 - accuracy: 0.8604 - val_loss: 0.8203 - val_accuracy: 0.7367\n",
      "Epoch 53/80\n",
      "448/448 [==============================] - 173s 386ms/step - loss: 0.3815 - accuracy: 0.8653 - val_loss: 0.8127 - val_accuracy: 0.7359\n",
      "Epoch 54/80\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.3754 - accuracy: 0.8663 - val_loss: 0.8171 - val_accuracy: 0.7395\n",
      "Epoch 55/80\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.3644 - accuracy: 0.8714 - val_loss: 0.8170 - val_accuracy: 0.7405\n",
      "Epoch 56/80\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.3609 - accuracy: 0.8719 - val_loss: 0.8022 - val_accuracy: 0.7455\n",
      "Epoch 57/80\n",
      "448/448 [==============================] - 173s 386ms/step - loss: 0.3475 - accuracy: 0.8768 - val_loss: 0.8275 - val_accuracy: 0.7395\n",
      "Epoch 58/80\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.3327 - accuracy: 0.8844 - val_loss: 0.8108 - val_accuracy: 0.7467\n",
      "Epoch 59/80\n",
      "448/448 [==============================] - 173s 385ms/step - loss: 0.3255 - accuracy: 0.8855 - val_loss: 0.8329 - val_accuracy: 0.7465\n",
      "Epoch 60/80\n",
      "448/448 [==============================] - 175s 391ms/step - loss: 0.3258 - accuracy: 0.8844 - val_loss: 0.7892 - val_accuracy: 0.7524\n",
      "Epoch 61/80\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.3153 - accuracy: 0.8882 - val_loss: 0.8044 - val_accuracy: 0.7511\n",
      "Epoch 62/80\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.3021 - accuracy: 0.8947 - val_loss: 0.8191 - val_accuracy: 0.7446\n",
      "Epoch 63/80\n",
      "448/448 [==============================] - 171s 382ms/step - loss: 0.3000 - accuracy: 0.8944 - val_loss: 0.7983 - val_accuracy: 0.7561\n",
      "Epoch 64/80\n",
      "448/448 [==============================] - 177s 397ms/step - loss: 0.2889 - accuracy: 0.8994 - val_loss: 0.8039 - val_accuracy: 0.7566\n",
      "Epoch 65/80\n",
      "448/448 [==============================] - 172s 383ms/step - loss: 0.2878 - accuracy: 0.8981 - val_loss: 0.8357 - val_accuracy: 0.7479\n",
      "Epoch 66/80\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.2758 - accuracy: 0.9028 - val_loss: 0.8099 - val_accuracy: 0.7586\n",
      "Epoch 67/80\n",
      "448/448 [==============================] - 174s 387ms/step - loss: 0.2712 - accuracy: 0.9046 - val_loss: 0.7999 - val_accuracy: 0.7617\n",
      "Epoch 68/80\n",
      "448/448 [==============================] - 173s 387ms/step - loss: 0.2690 - accuracy: 0.9058 - val_loss: 0.8016 - val_accuracy: 0.7593\n",
      "Epoch 69/80\n",
      "448/448 [==============================] - 173s 387ms/step - loss: 0.2668 - accuracy: 0.9061 - val_loss: 0.8050 - val_accuracy: 0.7546\n",
      "Epoch 70/80\n",
      "448/448 [==============================] - 176s 393ms/step - loss: 0.2623 - accuracy: 0.9081 - val_loss: 0.8507 - val_accuracy: 0.7540\n",
      "Epoch 71/80\n",
      "448/448 [==============================] - 173s 387ms/step - loss: 0.2532 - accuracy: 0.9122 - val_loss: 0.8302 - val_accuracy: 0.7522\n",
      "Epoch 72/80\n",
      "448/448 [==============================] - 173s 386ms/step - loss: 0.2491 - accuracy: 0.9134 - val_loss: 0.7996 - val_accuracy: 0.7660\n",
      "Epoch 73/80\n",
      "448/448 [==============================] - 173s 387ms/step - loss: 0.2422 - accuracy: 0.9165 - val_loss: 0.8196 - val_accuracy: 0.7606\n",
      "Epoch 74/80\n",
      "448/448 [==============================] - 173s 387ms/step - loss: 0.2334 - accuracy: 0.9189 - val_loss: 0.8283 - val_accuracy: 0.7616\n",
      "Epoch 75/80\n",
      "448/448 [==============================] - 183s 408ms/step - loss: 0.2345 - accuracy: 0.9191 - val_loss: 0.8193 - val_accuracy: 0.7631\n",
      "Epoch 76/80\n",
      "448/448 [==============================] - 195s 436ms/step - loss: 0.2349 - accuracy: 0.9193 - val_loss: 0.8546 - val_accuracy: 0.7568\n",
      "Epoch 77/80\n",
      "448/448 [==============================] - 195s 436ms/step - loss: 0.2278 - accuracy: 0.9202 - val_loss: 0.8291 - val_accuracy: 0.7602\n",
      "Epoch 78/80\n",
      "448/448 [==============================] - 194s 433ms/step - loss: 0.2277 - accuracy: 0.9218 - val_loss: 0.8288 - val_accuracy: 0.7582\n",
      "Epoch 79/80\n",
      "448/448 [==============================] - 218s 487ms/step - loss: 0.2187 - accuracy: 0.9248 - val_loss: 0.8455 - val_accuracy: 0.7637\n",
      "Epoch 80/80\n",
      "448/448 [==============================] - 212s 473ms/step - loss: 0.2133 - accuracy: 0.9255 - val_loss: 0.8232 - val_accuracy: 0.7613\n"
     ]
    }
   ],
   "source": [
    "#import required packages\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "#Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'archive/train',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "#Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "    'archive/test',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "#Create model structure\n",
    "emotion_detection_model = Sequential()\n",
    "\n",
    "emotion_detection_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_detection_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_detection_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_detection_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_detection_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_detection_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_detection_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_detection_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_detection_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_detection_model.add(Flatten())\n",
    "emotion_detection_model.add(Dense(1024, activation='relu'))\n",
    "emotion_detection_model.add(Dropout(0.5))\n",
    "emotion_detection_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "emotion_detection_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "# Train the neural network/model\n",
    "emotion_detection_model_info = emotion_detection_model.fit(\n",
    "        train_generator,\n",
    "        y=None,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=80,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64,\n",
    "        )\n",
    "\n",
    "# save model structure in json file\n",
    "model_json = emotion_detection_model.to_json()\n",
    "with open(\"emotion_detection_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save trained model weight in .h5 file\n",
    "emotion_detection_model.save_weights('emotion_detection_model.h5')\n",
    "\n",
    "# converting the model to TF lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(emotion_detection_model.h5)\n",
    "tflite_model = converter.convert()\n",
    "with open('model.tflite', 'wb') as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model()\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2892d292b0cc7c583c5859636aac84e4f2cca23263ca7e44f297b13e1423cd06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
